<!DOCTYPE html>
<html>

<head>
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">

<title>
    project8 - Advait Rane
</title>









<link rel="stylesheet" href="/css/main.min.493c84322283959a7d7d20f4f1e5ff98062b8fb190abd204adfdd782c63d858b.css" integrity="sha256-STyEMiKDlZp9fSD08eX/mAYrj7GQq9IErf3XgsY9hYs=" crossorigin="anonymous" media="screen">




  






<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Didact+Gothic">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="project8"/>
<meta name="twitter:description" content="Obstacle Avoidance for Visually Impaired Persons (2021)&nbsp;¶ Members - Advait Rane, Katie Foss
In this project, we simulated a device that uses Computer Vision (CV) to help a Visually Impaired Person (VIP) navigate around obstacles on a sidewalk. We further evaluated the simulated system against safety requirements defined using Signal Temporal Logic (STL).
We defined an environment with three types of obstacles - ground level (fire hydrant), head level (stop sign) and large ground level obstacle (bicycle)."/>

<meta property="og:title" content="project8" />
<meta property="og:description" content="Obstacle Avoidance for Visually Impaired Persons (2021)&nbsp;¶ Members - Advait Rane, Katie Foss
In this project, we simulated a device that uses Computer Vision (CV) to help a Visually Impaired Person (VIP) navigate around obstacles on a sidewalk. We further evaluated the simulated system against safety requirements defined using Signal Temporal Logic (STL).
We defined an environment with three types of obstacles - ground level (fire hydrant), head level (stop sign) and large ground level obstacle (bicycle)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://advaitrane.github.io/portfolio/projects/vip/" /><meta property="article:section" content="portfolio" />
<meta property="article:published_time" content="2022-09-11T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-09-11T00:00:00+00:00" />



    

    
    
    
    <title>
        
        Obstacle Avoidance for the Visually Impaired
        
    </title>
</head>

<body>
    
    
    <header class="wrap flex-container">
        <h1>Obstacle Avoidance for the Visually Impaired</h1>
    </header>
    
    <main class="wrap">
        
        <article role="article" class="flex-container">
<h3 id="obstacle-avoidance-for-visually-impaired-persons-2021" class="anchor-link"><a href="#obstacle-avoidance-for-visually-impaired-persons-2021">Obstacle Avoidance for Visually Impaired Persons (2021)<span class="pilcrow">&nbsp;¶</span></a></h3>
<p><p style="text-align:center;">
    <img src="/images/vip_cover.jpeg" alt="cover"  />
</p>
</p>
<p>Members - Advait Rane, Katie Foss</p>
<p>In this project, we simulated a device that uses Computer Vision (CV) to help a Visually Impaired Person (VIP) navigate around obstacles on a sidewalk. We further evaluated the simulated system against safety requirements defined using Signal Temporal Logic (STL).</p>
<p>We defined an environment with three types of obstacles - ground level (fire hydrant), head level (stop sign) and large ground level obstacle (bicycle). We used Unity to simulate this as a narrow sidewalk of fixed lenghth with bounds on either side and three randomly placed obstacles. Our devices uses an RGB-D camera and CV techniques to direct the VIP using 4 commands, telling them to go straight, left, right, or to stop. We defined three safety requirements - staying on the sidewalk, not colliding with obstacles, and reaching the end of the sidewalk.
<p style="text-align:center;">
    <img src="/images/vip_obstacles.jpeg" alt="obstacles"  />
</p>
</p>
<p>Our controller used three CV techniques to detect the sidewalk and obstacles:</p>
<ul>
<li>Canny edge detection</li>
<li>RGB-D Camera Depth perception</li>
<li>YOLO Object Detection</li>
</ul>
<p>Edge detection was done using OpenCV and Object detection was done using a pre-trained YOLOv4 model with Unity Barracuda. We divided the free area between the sidewalk bounds or any obstacle into three lanes and directed the user to use the straight, right, or left motion based on the free lane. If no lane is free we ask the user to stop.</p>
<p>To evaluate safety requirements, we converted the 3 requirements into STL formulae. We then evaluated each simulation run with these formulae using the RTAMT package in Python. The video below shows some of our successful runs.
<p style="text-align:center;">
    <img src="/images/DemosAllSuccess.mp4" alt="successful runs"  />
</p>
</p>
</article>
        

        
        
        <nav role="navigation" class="flex-container bottom-menu">
            
<hr />
<p>


    

    
        
            <a href="/about">about</a>
        
    
    
        
            &#183; 
            <a href="/portfolio">portfolio</a>
        
            &#183; 
            <a href="/basketball">basketball</a>
        
            &#183; 
            <a href="/writing">writing</a>
        
    
    &#183; 
    <a href="/">
        home
    </a>

</p>
        </nav>
        
        
    </main>
    
    <footer class="flex-container footer">
</footer>
    
    
</body>

</html>