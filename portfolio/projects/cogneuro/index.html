<!DOCTYPE html>
<html>

<head>
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">

<title>
    project5 - Advait Rane
</title>









<link rel="stylesheet" href="/css/main.min.9283c53fc58b6ba8aaa8a222a5286f6b78c28266fecd9ffdb0a957e5e3c162a3.css" integrity="sha256-koPFP8WLa6iqqKIipShva3jCgmb&#43;zZ/9sKlX5ePBYqM=" crossorigin="anonymous" media="screen">




  






<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Didact+Gothic">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="project5"/>
<meta name="twitter:description" content="Visual Perception of the Colour Spectrum (2019)&nbsp;¶ Supervisors - Mayur Jartarkar, Veeky Baths
I worked in the BITS Goa Cognitive Neuroscience Lab to study the human perception of the colour spectrum by classifying EEG data.
I initially worked on creating an android app to display colours through a VR headset to completely flush the subject’s field of vision. This would eliminate any distracting visuals from confounding the data. The display alternated between three colours at a time, either red-green-blue or cyan-magenta-yellow."/>

<meta property="og:title" content="project5" />
<meta property="og:description" content="Visual Perception of the Colour Spectrum (2019)&nbsp;¶ Supervisors - Mayur Jartarkar, Veeky Baths
I worked in the BITS Goa Cognitive Neuroscience Lab to study the human perception of the colour spectrum by classifying EEG data.
I initially worked on creating an android app to display colours through a VR headset to completely flush the subject’s field of vision. This would eliminate any distracting visuals from confounding the data. The display alternated between three colours at a time, either red-green-blue or cyan-magenta-yellow." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://advaitrane.github.io/portfolio/projects/cogneuro/" /><meta property="article:section" content="portfolio" />
<meta property="article:published_time" content="2020-11-29T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-11-29T00:00:00+00:00" />



    

    
    
    
    <title>
        
        Visual Perception of the Colour Spectrum
        
    </title>
</head>

<body>
    
    
    <header class="wrap flex-container">
        <h1>Visual Perception of the Colour Spectrum</h1>
    </header>
    
    <main class="wrap">
        
        <article role="article" class="flex-container">
<h3 id="visual-perception-of-the-colour-spectrum-2019" class="anchor-link"><a href="#visual-perception-of-the-colour-spectrum-2019">Visual Perception of the Colour Spectrum (2019)<span class="pilcrow">&nbsp;¶</span></a></h3>
<p><p style="text-align:center;">
    <img src="/images/cogneuro_cover.jpg" alt="cover"  />
</p>
</p>
<p>Supervisors - Mayur Jartarkar, Veeky Baths</p>
<p>I worked in the BITS Goa Cognitive Neuroscience Lab to study the human perception of the colour spectrum by classifying EEG data.</p>
<p>I initially worked on creating an android app to display colours through a VR headset to completely flush the subject’s field of vision. This would eliminate any distracting visuals from confounding the data. The display alternated between three colours at a time, either red-green-blue or cyan-magenta-yellow. The colour labels were transmitted and stored on the system running the EEG collection experiment. The app was created using the Google VR SDK for Android.</p>
<p>After building the app, we carried out experiments to collect EEG data from subjects using a 32-channel EEG headset. We used the visual area EEG data from channels corresponding to the occipital lobe to analyse the reaction elicited by different colours. We converted the time-series EEG data to the frequency-domain using Fast Fourier Transforms and analysed the mean frequency-domain behaviour for different colours. I leveraged different classification techniques, including support vector classifiers, neural networks, and gradient-boosted classification trees to classify the frequency-domain data by colour. The models learned to classify the data with an accuracy of about 85%, indicating that a pattern exists in the human perception of colours in the brain which can be learnt even by simple models.</p>
<p>The mean frequency-domain behaviour of the delta band frequencies for EEG data of different colours can be seen below.
<p style="text-align:center;">
    <img src="/images/VRCP_mean_delta.png" alt="VRCP_mean_delta"  />
</p>
</p>
<p>You can find the code for the android app <a href="https://github.com/advaitrane/VPoCS_RGB">here</a> and for the classification experiments <a href="https://github.com/advaitrane/VRCP">here</a></p>
</article>
        

        
        
        <nav role="navigation" class="flex-container bottom-menu">
            
<hr />
<p>


    

    
        
            <a href="/about">about</a>
        
    
    
        
            &#183; 
            <a href="/portfolio">portfolio</a>
        
            &#183; 
            <a href="/basketball">basketball</a>
        
            &#183; 
            <a href="/writing">writing</a>
        
    
    &#183; 
    <a href="/">
        home
    </a>

</p>
        </nav>
        
        
    </main>
    
    <footer class="flex-container footer">
</footer>
    
    
</body>

</html>